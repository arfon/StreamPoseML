{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AI Tango\n",
    "\n",
    "## Model Experiments"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, load in dependencies, as well as the ModelBuilder which is meant for rapidly iterating on various options for our datasets and models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pose_parser.pose_parser.learning import model_builder as mb\n",
    "from scipy.stats import randint\n",
    "\n",
    "model_builder = mb.ModelBuilder()\n",
    "\n",
    "value_map = {\n",
    "    \"weight_transfer_type\": {\n",
    "        \"Failure Weight Transfer\": 0,\n",
    "        \"Successful Weight Transfer\": 1,\n",
    "    },\n",
    "    \"step_type\": {\n",
    "        \"Left Step\": 0,\n",
    "        \"Right Step\": 1,\n",
    "    },\n",
    "}\n",
    "drop_list = [\"video_id\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a variety of datasets to choose from and more can be generated. Here is a list:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this one is the original \"avg dataset used\"\n",
    "# data_file = \"./data/annotated_videos/dataset_1678732901064497000.csv\"\n",
    "\n",
    "# this one includes more pooled stats (max)\n",
    "# data_file = \"./data/annotated_videos/dataset_1679002854718304000.csv\"\n",
    "\n",
    "# this one is 45 frame window pooled\n",
    "# data_file = \"./data/annotated_videos/dataset_1679015606654767000.csv\"\n",
    "\n",
    "# this one is 25 frame window pooled\n",
    "# data_file = \"./data/annotated_videos/dataset_1679016147487099000.csv\"\n",
    "\n",
    "# this one is a flat column representation frame by frame angles of a labeled 10 frame window\n",
    "# data_file = \"./data/annotated_videos/dataset_1679087888313443000.csv\"\n",
    "\n",
    "# this one is a flat column representation frame by frame angles of a labeled 25 frame window\n",
    "# data_file = \"./data/annotated_videos/dataset_1679103956737220000.csv\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model / Dataset comparisons"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're looking predict the target variable \"weight_transfer_type. Our dataset is pretty imbalanced, with most examples being a \"successful weight transfer\".\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "### Flat column representation, frame by frame angles of labeled 25 frame window"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_file = \"./data/annotated_videos/dataset_1679103956737220000.csv\"\n",
    "\n",
    "column_whitelist = [\n",
    "    # \"angles_max.line_5_6__line_6_7_angle_2d_degrees\",\n",
    "    # \"angles_std.line_5_6__line_25_26_angle_2d_degrees\",\n",
    "    # \"angles_avg.line_5_6__line_6_7_angle_2d_degrees\",\n",
    "    # \"angles_avg.line_8_9__line_9_10_angle_2d_degrees\",\n",
    "    # \"angles_max.line_5_6__line_25_26_angle_2d_degrees\",\n",
    "    # \"angles_max.line_2_3__line_25_26_angle_2d_degrees\",\n",
    "    # \"angles_avg.line_1_5__line_5_6_angle_2d_degrees\",\n",
    "    # \"angles_avg.line_2_3__line_25_26_angle_2d_degrees\",\n",
    "    # \"angles_std.line_1_5__line_5_6_angle_2d_degrees\",\n",
    "]\n",
    "drop_list = [\"video_id\"]\n",
    "model_builder.load_and_prep_dataset_from_csv(\n",
    "    path=data_file,\n",
    "    target=\"weight_transfer_type\",\n",
    "    value_map=value_map,\n",
    "    column_whitelist=column_whitelist,\n",
    "    drop_list=drop_list,\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "First, let's upsample the minority class by just randomly oversampling. Then train the data on a random forest classifier:\n",
    "\n",
    "Spec:\n",
    "* Num estimators 600\n",
    "* Max Depth 9\n",
    "* Max Leaf Notes: 63\n",
    "\n",
    "These features are compared to a well-performing AutoML model - SparseNormalizer, XGBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Balance for weight_transfer_type:\n",
      "1    965\n",
      "0    965\n",
      "Name: weight_transfer_type, dtype: int64\n",
      "Mean ROC AUC from cross validation: 0.963\n",
      "Min ROC AUC from cross validation: 0.939\n",
      "Max ROC AUC from cross validation: 0.993\n",
      "Confusion matrix:\n",
      "[[ 12  29]\n",
      " [ 11 231]]\n",
      "Accuracy: 0.8586572438162544\n",
      "Precision: 0.8884615384615384\n",
      "Recall: 0.9545454545454546\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.29      0.38        41\n",
      "           1       0.89      0.95      0.92       242\n",
      "\n",
      "    accuracy                           0.86       283\n",
      "   macro avg       0.71      0.62      0.65       283\n",
      "weighted avg       0.84      0.86      0.84       283\n",
      "\n",
      "Type Random Forest\n",
      "Data_file ./data/annotated_videos/dataset_1679103956737220000.csv\n",
      "AUC 0.6236141906873615\n",
      "Accuracy 0.8586572438162544\n",
      "Precision 0.8884615384615384\n",
      "Recall 0.9545454545454546\n",
      "Confusion_matrix [[ 12  29]\n",
      " [ 11 231]]\n",
      "Feature_importances [0.         0.00014901 0.00039894 ... 0.         0.         0.        ]\n"
     ]
    }
   ],
   "source": [
    "# mb.run_pca(num_components=5)\n",
    "model_builder.set_train_test_split(\n",
    "    balance_off_target=True,\n",
    "    upsample_minority=True,\n",
    "    downsample_majority=False,\n",
    "    use_SMOTE=False,\n",
    "    random_state=123,\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\": randint(50, 500),\n",
    "    \"max_depth\": randint(1, 20),\n",
    "    \"max_features\": randint(3, 20),\n",
    "}\n",
    "rf_params = {\n",
    "    # \"class_weight\": \"balanced_subsample\",\n",
    "    # \"class_weight\": \"balanced\",\n",
    "    \"n_estimators\": 600,\n",
    "    \"max_depth\": 9,\n",
    "    \"max_leaf_nodes\": 63,\n",
    "}\n",
    "\n",
    "model_builder.train_random_forest(\n",
    "    use_random_search=False, params=rf_params, param_dist=param_dist\n",
    ")\n",
    "model_builder.report()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These results show a fairly low AUC (Area under curve)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next try SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'ModelBuilder' object has no attribute 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# mb.run_pca(num_components=5)\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m model_builder\u001b[39m.\u001b[39;49mset_train_test_split(\n\u001b[1;32m      3\u001b[0m     balance_off_target\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      4\u001b[0m     upsample_minority\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      5\u001b[0m     downsample_majority\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[1;32m      6\u001b[0m     use_SMOTE\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m      7\u001b[0m     random_state\u001b[39m=\u001b[39;49m\u001b[39m123\u001b[39;49m,\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m param_dist \u001b[39m=\u001b[39m {\n\u001b[1;32m     11\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mn_estimators\u001b[39m\u001b[39m\"\u001b[39m: randint(\u001b[39m50\u001b[39m, \u001b[39m500\u001b[39m),\n\u001b[1;32m     12\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmax_depth\u001b[39m\u001b[39m\"\u001b[39m: randint(\u001b[39m1\u001b[39m, \u001b[39m20\u001b[39m),\n\u001b[1;32m     13\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmax_features\u001b[39m\u001b[39m\"\u001b[39m: randint(\u001b[39m3\u001b[39m, \u001b[39m20\u001b[39m),\n\u001b[1;32m     14\u001b[0m }\n\u001b[1;32m     15\u001b[0m rf_params \u001b[39m=\u001b[39m {\n\u001b[1;32m     16\u001b[0m     \u001b[39m# \"class_weight\": \"balanced_subsample\",\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     \u001b[39m# \"class_weight\": \"balanced\",\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     20\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mmax_leaf_nodes\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m63\u001b[39m,\n\u001b[1;32m     21\u001b[0m }\n",
      "File \u001b[0;32m~/Dev-Local/pose_parser/pose_parser/pose_parser/learning/model_builder.py:57\u001b[0m, in \u001b[0;36mModelBuilder.set_train_test_split\u001b[0;34m(self, test_size, random_state, balance_off_target, upsample_minority, downsample_majority, use_SMOTE)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mset_train_test_split\u001b[39m(\n\u001b[1;32m     39\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     40\u001b[0m     test_size: \u001b[39mfloat\u001b[39m \u001b[39m=\u001b[39m \u001b[39m0.2\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     45\u001b[0m     use_SMOTE: \u001b[39mbool\u001b[39m \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m,\n\u001b[1;32m     46\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     47\u001b[0m     \u001b[39m\"\"\"Set the train test split based on test size (80/20 by default)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \n\u001b[1;32m     49\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \n\u001b[1;32m     55\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m     56\u001b[0m     X_train, X_test, y_train, y_test \u001b[39m=\u001b[39m train_test_split(\n\u001b[0;32m---> 57\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mX, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39my, test_size\u001b[39m=\u001b[39mtest_size, random_state\u001b[39m=\u001b[39mrandom_state\n\u001b[1;32m     58\u001b[0m     )\n\u001b[1;32m     59\u001b[0m     \u001b[39mif\u001b[39;00m balance_off_target:\n\u001b[1;32m     60\u001b[0m         majority_class \u001b[39m=\u001b[39m X_train[X_train[\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtarget] \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'ModelBuilder' object has no attribute 'X'"
     ]
    }
   ],
   "source": [
    "# mb.run_pca(num_components=5)\n",
    "model_builder.set_train_test_split(\n",
    "    balance_off_target=True,\n",
    "    upsample_minority=True,\n",
    "    downsample_majority=False,\n",
    "    use_SMOTE=True,\n",
    "    random_state=123,\n",
    ")\n",
    "\n",
    "param_dist = {\n",
    "    \"n_estimators\": randint(50, 500),\n",
    "    \"max_depth\": randint(1, 20),\n",
    "    \"max_features\": randint(3, 20),\n",
    "}\n",
    "rf_params = {\n",
    "    # \"class_weight\": \"balanced_subsample\",\n",
    "    # \"class_weight\": \"balanced\",\n",
    "    \"n_estimators\": 600,\n",
    "    \"max_depth\": 9,\n",
    "    \"max_leaf_nodes\": 63,\n",
    "}\n",
    "\n",
    "model_builder.train_random_forest(\n",
    "    use_random_search=False, params=rf_params, param_dist=param_dist\n",
    ")\n",
    "model_builder.report()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" WRITE NOTES ON THIS RUN HERE \"\"\"\n",
    "notes = \"\"\"\n",
    "    Dataset notes:\n",
    "    Flat column representation of 10 windows of frame data angles\n",
    "\n",
    "    Model notes:\n",
    "    PCA on a rand search Random Forest. \n",
    "    \"\"\"\n",
    "if False:\n",
    "    model_builder.save_model_and_datasets(notes=notes)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pose_parser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
