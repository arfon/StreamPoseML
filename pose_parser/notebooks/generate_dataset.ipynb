{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build Datasets"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handle imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-06-19 13:09:07.330066: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import time\n",
    "# Reloader\n",
    "import importlib\n",
    "\n",
    "# Assuming the notebook is in the \"notebooks\" folder, we go one level up to include the \"pose_parser\" package.\n",
    "parent_directory = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "\n",
    "if parent_directory not in sys.path:\n",
    "    sys.path.append(parent_directory)\n",
    "\n",
    "import pose_parser.jobs.process_videos_job as pv\n",
    "import pose_parser.jobs.build_and_format_dataset_job as data_builder \n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### I/O File Locations\n",
    "\n",
    "Relative to this directory ./pose_parser/notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The location of video files\n",
    "source_videos_directory = \"../../source_videos\"\n",
    "\n",
    "# The location of Dataloop Annotations corresponding to each video\n",
    "source_annotations_directory = \"../../source_annotations\"\n",
    "\n",
    "# The location to output sequence data\n",
    "sequence_data_directory = \"../../data/sequences\"\n",
    "\n",
    "# The location to output keypoint data\n",
    "keypoints_data_directory = \"../../data/keypoints\"\n",
    "\n",
    "# The location to output datasets\n",
    "merged_annotation_output_directory = \"../../data/annotated_videos\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Keypoint and Sequence Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(pv)\n",
    "\n",
    "# give a timestamped folder to not overwrite\n",
    "folder = f\"run-preproccessed-{time.time_ns()}\"  \n",
    "keypoints_path = f\"{keypoints_data_directory}/{folder}\"\n",
    "sequence_path = f\"{sequence_data_directory}/{folder}\"\n",
    "\n",
    "pv.ProcessVideosJob().process_videos(\n",
    "    src_videos_path=source_videos_directory,\n",
    "    output_keypoints_data_path=keypoints_path,\n",
    "    output_sequence_data_path=sequence_path,\n",
    "    write_keypoints_to_file=True,\n",
    "    write_serialized_sequence_to_file=True,\n",
    "    limit=None,\n",
    "    configuration={},\n",
    "    preprocess_video=True,\n",
    "    return_output=False\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Datasets from Keypoints + Sequence Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Dataset\n",
    "\n",
    "TODO enumerate all the options here... \n",
    "\n",
    "\n",
    "#### Labels\n",
    "```\n",
    "step_type\n",
    "weight_transfer_type\n",
    "```\n",
    "#### Segmentation Strategy\n",
    "```\n",
    "flatten_into_columns\n",
    "flatten_on_example\n",
    "split_on_label\n",
    "window\n",
    "none\n",
    "```\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split on Step Type, pooled temporal dynamics with angles and distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(data_builder)\n",
    "\n",
    "# sequence generated on 3/24/23 with new normalized values\n",
    "# sequence_data_directory= \"../../data/sequences/run-1679706020787139000\"\n",
    "\n",
    "# sequence generated on 3/24/23 with new normalized values\n",
    "\n",
    "db = data_builder.BuildAndFormatDatasetJob()\n",
    "dataset = db.build_dataset_from_data_files(\n",
    "    annotations_data_directory=source_annotations_directory,\n",
    "    sequence_data_directory=sequence_data_directory,\n",
    "    limit=None,\n",
    ")\n",
    "\n",
    "formatted_dataset = db.format_dataset(\n",
    "    dataset=dataset,\n",
    "    pool_frame_data_by_clip=True,\n",
    "    decimal_precision=4,\n",
    "    include_unlabeled_data=True,\n",
    "    include_angles=True,\n",
    "    include_distances=True,\n",
    "    include_normalized=True,\n",
    "    segmentation_strategy=\"split_on_label\",\n",
    "    segmentation_splitter_label=\"step_type\",\n",
    "    segmentation_window=None,\n",
    "    segmentation_window_label=\"weight_transfer_type\",\n",
    ")\n",
    "\n",
    "db.write_dataset_to_csv(\n",
    "    csv_location=merged_annotation_output_directory,\n",
    "    formatted_dataset=formatted_dataset,\n",
    "    filename=\"pooled_angles_distances_full_examples\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split on Step Type, pooled temporal dynamics with angles and distances, only the last 10 frames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(data_builder)\n",
    "\n",
    "# sequence generated on 3/24/23 with new normalized values\n",
    "sequence_data_directory= \"../../data/sequences/run-1679706020787139000\"\n",
    "\n",
    "db = data_builder.BuildAndFormatDatasetJob()\n",
    "dataset = db.build_dataset_from_data_files(\n",
    "    annotations_data_directory=source_annotations_directory,\n",
    "    sequence_data_directory=sequence_data_directory,\n",
    "    limit=None,\n",
    ")\n",
    "\n",
    "formatted_dataset = db.format_dataset(\n",
    "    dataset=dataset,\n",
    "    pool_frame_data_by_clip=True,\n",
    "    decimal_precision=4,\n",
    "    include_unlabeled_data=True,\n",
    "    include_angles=True,\n",
    "    include_distances=True,\n",
    "    include_normalized=True,\n",
    "    segmentation_strategy=\"split_on_label\",\n",
    "    segmentation_splitter_label=\"step_type\",\n",
    "    segmentation_window=10,\n",
    "    segmentation_window_label=\"weight_transfer_type\",\n",
    ")\n",
    "\n",
    "db.write_dataset_to_csv(\n",
    "    csv_location=merged_annotation_output_directory,\n",
    "    formatted_dataset=formatted_dataset,\n",
    "    filename=\"pooled_angles_distances_last_10_frames\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten columns over 10 frame window on step type (arbitrary start / end)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(data_builder)\n",
    "\n",
    "# sequence generated on 3/24/23 with new normalized values\n",
    "sequence_data_directory= \"../../data/sequences/run-1679706020787139000\"\n",
    "\n",
    "db = data_builder.BuildAndFormatDatasetJob()\n",
    "dataset = db.build_dataset_from_data_files(\n",
    "    annotations_data_directory=source_annotations_directory,\n",
    "    sequence_data_directory=sequence_data_directory,\n",
    "    limit=None,\n",
    ")\n",
    "\n",
    "formatted_dataset = db.format_dataset(\n",
    "    dataset=dataset,\n",
    "    pool_frame_data_by_clip=True,\n",
    "    decimal_precision=4,\n",
    "    include_unlabeled_data=True,\n",
    "    include_angles=True,\n",
    "    include_distances=True,\n",
    "    include_normalized=True,\n",
    "    segmentation_strategy=\"split_on_label\",\n",
    "    segmentation_splitter_label=\"step_type\",\n",
    "    segmentation_window=10,\n",
    "    segmentation_window_label=\"weight_transfer_type\",\n",
    ")\n",
    "\n",
    "db.write_dataset_to_csv(\n",
    "    csv_location=merged_annotation_output_directory,\n",
    "    formatted_dataset=formatted_dataset,\n",
    "    filename=\"pooled_angles_distances_last_10_frames\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten on a 10 frame window based on complete training examples (the end of the example will flatten the previous 10 frames into a training row0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(data_builder)\n",
    "\n",
    "# sequence generated on 3/24/23 with new normalized values\n",
    "sequence_data_directory= \"../../data/sequences/run-1679706020787139000\"\n",
    "\n",
    "db = data_builder.BuildAndFormatDatasetJob()\n",
    "dataset = db.build_dataset_from_data_files(\n",
    "    annotations_data_directory=source_annotations_directory,\n",
    "    sequence_data_directory=sequence_data_directory,\n",
    "    limit=None,\n",
    ")\n",
    "\n",
    "formatted_dataset = db.format_dataset(\n",
    "    dataset=dataset,\n",
    "    pool_frame_data_by_clip=False,\n",
    "    decimal_precision=4,\n",
    "    include_unlabeled_data=True,\n",
    "    include_angles=True,\n",
    "    include_distances=True,\n",
    "    include_normalized=True,\n",
    "    segmentation_strategy=\"flatten_on_example\",\n",
    "    segmentation_splitter_label=\"step_type\",\n",
    "    segmentation_window=10,\n",
    "    segmentation_window_label=\"weight_transfer_type\",\n",
    ")\n",
    "\n",
    "db.write_dataset_to_csv(\n",
    "    csv_location=merged_annotation_output_directory,\n",
    "    formatted_dataset=formatted_dataset,\n",
    "    filename=\"flatten_on_example_10_frames_2\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Flatten on a 25 frame window based on complete training examples (the end of the example will flatten the previous 25 frames into a training row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "importlib.reload(data_builder)\n",
    "\n",
    "# sequence generated on 3/24/23 with new normalized values\n",
    "# sequence_data_directory= \"../../data/sequences/run-1679706020787139000\"\n",
    "sequence_data_directory = \"../../data/sequences/run-preproccessed-1680117203184086000\"\n",
    "\n",
    "\n",
    "db = data_builder.BuildAndFormatDatasetJob()\n",
    "dataset = db.build_dataset_from_data_files(\n",
    "    annotations_data_directory=source_annotations_directory,\n",
    "    sequence_data_directory=sequence_data_directory,\n",
    "    limit=None,\n",
    ")\n",
    "\n",
    "formatted_dataset = db.format_dataset(\n",
    "    dataset=dataset,\n",
    "    pool_frame_data_by_clip=False,\n",
    "    decimal_precision=4,\n",
    "    include_unlabeled_data=True,\n",
    "    include_angles=True,\n",
    "    include_distances=True,\n",
    "    include_normalized=True,\n",
    "    segmentation_strategy=\"flatten_on_example\",\n",
    "    segmentation_splitter_label=\"step_type\",\n",
    "    segmentation_window=25,\n",
    "    segmentation_window_label=\"weight_transfer_type\",\n",
    ")\n",
    "\n",
    "db.write_dataset_to_csv(\n",
    "    csv_location=merged_annotation_output_directory,\n",
    "    formatted_dataset=formatted_dataset,\n",
    "    filename=\"preprocessed_flatten_on_example_25_frames_2\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset with all frames as rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequence_data_directory = \"../../data/sequences/run-preproccessed-1680117203184086000\"\n",
    "db = data_builder.BuildAndFormatDatasetJob()\n",
    "dataset = db.build_dataset_from_data_files(\n",
    "    annotations_data_directory=source_annotations_directory,\n",
    "    sequence_data_directory=sequence_data_directory,\n",
    "    limit=None,\n",
    ")\n",
    "\n",
    "formatted_dataset = db.format_dataset(\n",
    "    dataset=dataset,\n",
    "    pool_frame_data_by_clip=False,\n",
    "    decimal_precision=4,\n",
    "    include_unlabeled_data=True,\n",
    "    include_angles=True,\n",
    "    include_distances=True,\n",
    "    include_normalized=True,\n",
    "    segmentation_strategy=\"none\",\n",
    "    segmentation_splitter_label=\"step_type\",\n",
    "    segmentation_window=25,\n",
    "    segmentation_window_label=\"weight_transfer_type\",\n",
    ")\n",
    "\n",
    "db.write_dataset_to_csv(\n",
    "    csv_location=merged_annotation_output_directory,\n",
    "    formatted_dataset=formatted_dataset,\n",
    "    filename=\"preprocessed_all_rows-5-9-23.csv\",\n",
    "    pool_frame_data_by_clip=False,\n",
    "    decimal_precision=4,\n",
    "    include_unlabeled_data=True,\n",
    "    include_angles=False,\n",
    "    include_distances=False,\n",
    "    include_normalized=False,\n",
    "    segmentation_strategy=\"none\",\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset with raw x, y, z joint data, with one frame per row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importlib.reload(data_builder)\n",
    "\n",
    "sequence_data_directory = \"../../data/sequences/run-preproccessed-1680117203184086000\"\n",
    "db = data_builder.BuildAndFormatDatasetJob()\n",
    "dataset = db.build_dataset_from_data_files(\n",
    "    annotations_data_directory=source_annotations_directory,\n",
    "    sequence_data_directory=sequence_data_directory,\n",
    "    limit=None,\n",
    ")\n",
    "\n",
    "formatted_dataset = db.format_dataset(\n",
    "    dataset=dataset,\n",
    "    pool_frame_data_by_clip=False,\n",
    "    decimal_precision=4,\n",
    "    include_unlabeled_data=True,\n",
    "    include_joints=True,\n",
    "    include_z_axis=True,\n",
    "    include_angles=False,\n",
    "    include_distances=False,\n",
    "    include_normalized=False,\n",
    "    segmentation_strategy=\"none\",\n",
    ")\n",
    "\n",
    "db.write_dataset_to_csv(\n",
    "    csv_location=merged_annotation_output_directory,\n",
    "    formatted_dataset=formatted_dataset,\n",
    "    filename=\"preprocessed_frame_joint_data-6-19-23\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pose_parser",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
